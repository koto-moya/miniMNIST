{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "acabbb30-9816-447d-85df-7a514e0ae2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available on this device.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "import os\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.io import read_image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"MPS is available on this device.\")\n",
    "    # Set the PyTorch device to MPS\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1cb16757-81a0-4f66-b791-0d5b4225b9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, transform=None, target_transform=None):\n",
    "        self.chunked = pd.read_csv(annotations_file, chunksize=60000)\n",
    "        self.img_labels = next(self.chunked)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = torch.tensor(self.img_labels.iloc[idx, :1].values, device = device)\n",
    "        image = torch.tensor(self.img_labels.iloc[idx, 1:].values, dtype=torch.float, device = device)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "class Mnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mnet, self).__init__()\n",
    "        self.l1 = nn.Linear(784, 128)\n",
    "        self.act = nn.ReLU()\n",
    "        self.l2 = nn.Linear(128, 30)\n",
    "        self.l3 = nn.Linear(30,10)\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.act(x)\n",
    "        x = self.l3(x)\n",
    "        return x\n",
    "\n",
    "def validate_epoch(model, dat):\n",
    "    accs = [batch_accuracy(model(x),y) for x,y in dat]\n",
    "    return round(torch.stack(accs).mean().item(), 4)\n",
    "\n",
    "def batch_accuracy(x, y):\n",
    "    preds = softmax(x)\n",
    "    predicted_value = torch.argmax(preds, dim=1)\n",
    "    trgts = y.flatten()\n",
    "    bools = predicted_value == trgts\n",
    "    accs = bools.to(torch.float).mean()\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3cc9c163-855d-4ea6-92b0-f16efea45480",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = CustomImageDataset(\"data/mnist_train.csv\")\n",
    "valid_dl = CustomImageDataset(\"data/mnist_test.csv\")\n",
    "train_data = DataLoader(dl, batch_size=128, shuffle=True)\n",
    "test_data = DataLoader(valid_dl, batch_size=128, shuffle=True)\n",
    "#model = nn.Sequential(nn.Linear(784, 128), nn.ReLU(), nn.Linear(128, 10), nn.ReLU())\n",
    "model = Mnet().to(device)\n",
    "opt = optim.Adam(model.parameters()) #optim.SGD(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "cb954d06-761f-4b71-8217-1858dc73923a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9742, loss: 0.006378551479429007: 100%|████████████████████████████████████████████████████████████████████████| 10/10 [00:36<00:00,  3.67s/it]\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "losses, accuracies = [], [] \n",
    "for i in (r := trange(epochs)):\n",
    "    for x, y in train_data:\n",
    "        p = model(x)\n",
    "        loss = loss_fn(p, y.flatten())\n",
    "        losses.append(loss)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    accuracy = validate_epoch(model, test_data)\n",
    "    accuracies.append(accuracy)\n",
    "    r.set_description(f\"accuracy: {accuracy}, loss: {loss.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "51852a07-a297-4aa2-9016-75e63a0b457e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 784])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e749fe32-ecae-412a-b855-47ded8413ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
